{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6677809,"sourceType":"datasetVersion","datasetId":3852662}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\n\nsecret = {\"username\":\"abhay1704\",\"key\":\"c29c06b6ec949fc93f5a72b99420ff2a\"}\njson.dump(secret, open('/root/.config/kaggle/kaggle.json', 'w'))\n\n!kaggle kernels output abhay1704/include-finetuned -p /kaggle/working/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:26:12.715139Z","iopub.execute_input":"2024-11-25T18:26:12.715948Z","iopub.status.idle":"2024-11-25T18:34:39.325623Z","shell.execute_reply.started":"2024-11-25T18:26:12.715907Z","shell.execute_reply":"2024-11-25T18:34:39.324745Z"}},"outputs":[{"name":"stdout","text":"Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.config/kaggle/kaggle.json'\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/model.safetensors\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/optimizer.pt\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/preprocessor_config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/rng_state.pth\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/scheduler.pt\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/trainer_state.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-13149/training_args.bin\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/model.safetensors\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/optimizer.pt\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/preprocessor_config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/rng_state.pth\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/scheduler.pt\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/trainer_state.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/checkpoint-14610/training_args.bin\nOutput file downloaded to /kaggle/working/timesformer-finetuned/config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/idx_to_class.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/model.safetensors\nOutput file downloaded to /kaggle/working/timesformer-finetuned/preprocessor_config.json\nOutput file downloaded to /kaggle/working/timesformer-finetuned/training_args.bin\nKernel log downloaded to /kaggle/working/include-finetuned.log \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoImageProcessor, TimesformerForVideoClassification\nimport cv2\nimport torch\n\nprocessor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\nidx_to_class = json.load(open('/kaggle/working/timesformer-finetuned/idx_to_class.json', 'r'))\nclass_to_idx = {y:x for x,y in idx_to_class.items()}\n\nmodel = TimesformerForVideoClassification.from_pretrained(\n    '/kaggle/working/timesformer-finetuned',\n    num_labels=len(class_to_idx),  \n    ignore_mismatched_sizes=True  \n)\n\n\n# Step 7: Inference Function\ndef predict_video(video_path):\n    # Load video frames\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        raise ValueError(\"Error: Could not open video file.\")\n\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    frame_step = max(total_frames // 8, 1)\n\n    video_frames = []\n    for i in range(8):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_step)\n        ret, frame = cap.read()\n        if ret:\n            # Resize frame to 224x224 and convert to RGB\n            frame_resized = cv2.resize(frame, (224, 224))\n            frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n            video_frames.append(frame_rgb)\n        else:\n            break\n\n    cap.release()\n\n    # Process frames\n    inputs = processor(images=[video_frames], return_tensors=\"pt\").to(model.device)\n\n    # Make prediction\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        predicted_class_idx = logits.argmax(-1).item()\n\n    # Map index to class name\n    idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n    predicted_class = idx_to_class[str(predicted_class_idx)]\n\n    print(f\"Predicted class: {predicted_class}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:47:47.162198Z","iopub.execute_input":"2024-11-25T18:47:47.163030Z","iopub.status.idle":"2024-11-25T18:47:48.412792Z","shell.execute_reply.started":"2024-11-25T18:47:47.162993Z","shell.execute_reply":"2024-11-25T18:47:48.411863Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# idx_to_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:47:37.825442Z","iopub.execute_input":"2024-11-25T18:47:37.825795Z","iopub.status.idle":"2024-11-25T18:47:37.829775Z","shell.execute_reply.started":"2024-11-25T18:47:37.825766Z","shell.execute_reply":"2024-11-25T18:47:37.828851Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"predict_video('/kaggle/input/include/Adjectives_2of8/Adjectives/11. rich/MVI_9596.MOV')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:47:51.607804Z","iopub.execute_input":"2024-11-25T18:47:51.608721Z","iopub.status.idle":"2024-11-25T18:47:54.180115Z","shell.execute_reply.started":"2024-11-25T18:47:51.608673Z","shell.execute_reply":"2024-11-25T18:47:54.179067Z"}},"outputs":[{"name":"stdout","text":"Predicted class: rich\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"predict_video('/kaggle/input/include/Home_3of4/Home/40. Paint/MVI_4413.MOV')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:48:27.800827Z","iopub.execute_input":"2024-11-25T18:48:27.801170Z","iopub.status.idle":"2024-11-25T18:48:30.453541Z","shell.execute_reply.started":"2024-11-25T18:48:27.801139Z","shell.execute_reply":"2024-11-25T18:48:30.452562Z"}},"outputs":[{"name":"stdout","text":"Predicted class: paint\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"predict_video('/kaggle/input/include/People_5of5/People/80. Adult/MVI_3825.MOV')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T18:48:58.215679Z","iopub.execute_input":"2024-11-25T18:48:58.216047Z","iopub.status.idle":"2024-11-25T18:49:01.361872Z","shell.execute_reply.started":"2024-11-25T18:48:58.216015Z","shell.execute_reply":"2024-11-25T18:49:01.360854Z"}},"outputs":[{"name":"stdout","text":"Predicted class: adult\n","output_type":"stream"}],"execution_count":23}]}